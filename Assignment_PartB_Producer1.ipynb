{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producer 1\n",
    "\n",
    "Write a python program that loads all the data from\n",
    "climate_streaming.csv and randomly (with replacement) feed the data to the\n",
    "stream every 10 seconds. You will need to append additional information such as producer information to identify the producer and created date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka3 import KafkaProducer\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "climate_streaming_df = pd.read_csv(\"dataset/climate_streaming.csv\")\n",
    "print(climate_streaming_df.dtypes)\n",
    "\n",
    "# striping whitespace from column and separating precipitation type\n",
    "climate_streaming_df.rename(columns={\"precipitation \": \"precipitation\"}, inplace=True)\n",
    "climate_streaming_df[\"precipitation_type\"] = (\n",
    "    climate_streaming_df[\"precipitation\"].str.strip().str[-1]\n",
    ")\n",
    "climate_streaming_df[\"precipitation\"] = (\n",
    "    climate_streaming_df[\"precipitation\"].str.strip().str[:-1].astype(float)\n",
    ")\n",
    "\n",
    "climate_streaming_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing mongo connection and setting up database\n",
    "client = MongoClient()\n",
    "db = client.fit3182_assignment_db\n",
    "collection = db.climate_historic\n",
    "\n",
    "# finding latest date\n",
    "result = collection.find().sort(\"date\", -1).limit(1)\n",
    "latest_date = list(result)[0][\"date\"]\n",
    "latest_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    dataset = []\n",
    "    for index, row in climate_streaming_df.iterrows():\n",
    "        data = row.to_dict()\n",
    "        dataset.append(data)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def publish_message(producer_instance, topic_name, data):\n",
    "    try:\n",
    "        # send message to kafka asynchronously\n",
    "        producer_instance.send(topic_name, value=data)\n",
    "        # wait for all outstanding message to be persisted to disk\n",
    "        producer_instance.flush()\n",
    "        print(\"Message published successfully. Data: \" + str(data))\n",
    "    except Exception as ex:\n",
    "        print(\"Exception in publishing message.\")\n",
    "        print(str(ex))\n",
    "\n",
    "\n",
    "def connect_kafka_producer(host):\n",
    "    _producer = None\n",
    "    try:\n",
    "        # serializer to serialize data to json instead of string\n",
    "        _producer = KafkaProducer(\n",
    "            bootstrap_servers=[f\"{host}:9092\"],\n",
    "            value_serializer=lambda x: dumps(x).encode(\"ascii\"),\n",
    "            api_version=(0, 10),\n",
    "        )\n",
    "    except Exception as ex:\n",
    "        print(\"Exception while connecting Kafka.\")\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC = \"climate\"\n",
    "HOST = \"localhost\"\n",
    "\n",
    "producer = connect_kafka_producer(HOST)\n",
    "dataset = process_data()\n",
    "current_date = latest_date\n",
    "\n",
    "print(\"Publishing records..\")\n",
    "while True:\n",
    "    # increment date after every iteration\n",
    "    current_date += dt.timedelta(days=1)\n",
    "\n",
    "    # get random row and add metadata with replacement\n",
    "    selection = random.choice(dataset)\n",
    "    # transform date to string to be serialized\n",
    "    selection[\"date\"] = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # adding metadata field\n",
    "    # producer id to identify type of producer\n",
    "    # station - set as constant to conform to data model\n",
    "    selection[\"producer_id\"] = \"climate_producer\"\n",
    "    selection[\"station\"] = 948700\n",
    "\n",
    "    publish_message(producer, TOPIC, selection)\n",
    "\n",
    "    sleep(10)  # sleep for 10 seconds before publishing next message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asgn_3",
   "language": "python",
   "name": "asgn_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
